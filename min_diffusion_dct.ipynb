{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "min_diffusion_dct.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNMm0sJNfAYoRN3tCiMMNpO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sean-halpin/diffusion_models/blob/main/min_diffusion_dct.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/images/"
      ],
      "metadata": {
        "id": "Llm5lF5Rx32V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5Nvg8EauCEl"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Extremely Minimalistic Implementation of DDPM\n",
        "\n",
        "https://arxiv.org/abs/2006.11239\n",
        "\n",
        "Everything is self contained. (Except for pytorch and torchvision... of course)\n",
        "\n",
        "run it with `python superminddpm.py`\n",
        "\"\"\"\n",
        "\n",
        "from typing import Dict, Tuple\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image, make_grid\n",
        "\n",
        "\n",
        "def ddpm_schedules(beta1: float, beta2: float, T: int) -> Dict[str, torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Returns pre-computed schedules for DDPM sampling, training process.\n",
        "    \"\"\"\n",
        "    assert beta1 < beta2 < 1.0, \"beta1 and beta2 must be in (0, 1)\"\n",
        "\n",
        "    beta_t = (beta2 - beta1) * torch.arange(0, T + 1, dtype=torch.float32) / T + beta1\n",
        "    sqrt_beta_t = torch.sqrt(beta_t)\n",
        "    alpha_t = 1 - beta_t\n",
        "    log_alpha_t = torch.log(alpha_t)\n",
        "    alphabar_t = torch.cumsum(log_alpha_t, dim=0).exp()\n",
        "\n",
        "    sqrtab = torch.sqrt(alphabar_t)\n",
        "    oneover_sqrta = 1 / torch.sqrt(alpha_t)\n",
        "\n",
        "    sqrtmab = torch.sqrt(1 - alphabar_t)\n",
        "    mab_over_sqrtmab_inv = (1 - alpha_t) / sqrtmab\n",
        "\n",
        "    return {\n",
        "        \"alpha_t\": alpha_t,  # \\alpha_t\n",
        "        \"oneover_sqrta\": oneover_sqrta,  # 1/\\sqrt{\\alpha_t}\n",
        "        \"sqrt_beta_t\": sqrt_beta_t,  # \\sqrt{\\beta_t}\n",
        "        \"alphabar_t\": alphabar_t,  # \\bar{\\alpha_t}\n",
        "        \"sqrtab\": sqrtab,  # \\sqrt{\\bar{\\alpha_t}}\n",
        "        \"sqrtmab\": sqrtmab,  # \\sqrt{1-\\bar{\\alpha_t}}\n",
        "        \"mab_over_sqrtmab\": mab_over_sqrtmab_inv,  # (1-\\alpha_t)/\\sqrt{1-\\bar{\\alpha_t}}\n",
        "    }\n",
        "\n",
        "\n",
        "blk = lambda ic, oc: nn.Sequential(\n",
        "    nn.Conv2d(ic, oc, 7, padding=3),\n",
        "    nn.BatchNorm2d(oc),\n",
        "    nn.LeakyReLU(),\n",
        ")\n",
        "\n",
        "\n",
        "class DummyEpsModel(nn.Module):\n",
        "    \"\"\"\n",
        "    This should be unet-like, but let's don't think about the model too much :P\n",
        "    Basically, any universal R^n -> R^n model should work.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_channel: int) -> None:\n",
        "        super(DummyEpsModel, self).__init__()\n",
        "        self.conv = nn.Sequential(  # with batchnorm\n",
        "            blk(n_channel, 64),\n",
        "            blk(64, 128),\n",
        "            blk(128, 256),\n",
        "            blk(256, 512),\n",
        "            blk(512, 256),\n",
        "            blk(256, 128),\n",
        "            blk(128, 64),\n",
        "            nn.Conv2d(64, n_channel, 3, padding=1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, t) -> torch.Tensor:\n",
        "        # Lets think about using t later. In the paper, they used Tr-like positional embeddings.\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class DDPM(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        eps_model: nn.Module,\n",
        "        betas: Tuple[float, float],\n",
        "        n_T: int,\n",
        "        criterion: nn.Module = nn.MSELoss(),\n",
        "    ) -> None:\n",
        "        super(DDPM, self).__init__()\n",
        "        self.eps_model = eps_model\n",
        "\n",
        "        # register_buffer allows us to freely access these tensors by name. It helps device placement.\n",
        "        for k, v in ddpm_schedules(betas[0], betas[1], n_T).items():\n",
        "            self.register_buffer(k, v)\n",
        "\n",
        "        self.n_T = n_T\n",
        "        self.criterion = criterion\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Makes forward diffusion x_t, and tries to guess epsilon value from x_t using eps_model.\n",
        "        This implements Algorithm 1 in the paper.\n",
        "        \"\"\"\n",
        "\n",
        "        _ts = torch.randint(1, self.n_T, (x.shape[0],)).to(\n",
        "            x.device\n",
        "        )  # t ~ Uniform(0, n_T)\n",
        "        eps = torch.randn_like(x)  # eps ~ N(0, 1)\n",
        "\n",
        "        x_t = (\n",
        "            self.sqrtab[_ts, None, None, None] * x\n",
        "            + self.sqrtmab[_ts, None, None, None] * eps\n",
        "        )  # This is the x_t, which is sqrt(alphabar) x_0 + sqrt(1-alphabar) * eps\n",
        "        # We should predict the \"error term\" from this x_t. Loss is what we return.\n",
        "\n",
        "        return self.criterion(eps, self.eps_model(x_t, _ts / self.n_T))\n",
        "\n",
        "    def sample(self, n_sample: int, size, device) -> torch.Tensor:\n",
        "\n",
        "        x_i = torch.randn(n_sample, *size).to(device)  # x_T ~ N(0, 1)\n",
        "\n",
        "        # This samples accordingly to Algorithm 2. It is exactly the same logic.\n",
        "        for i in range(self.n_T, 0, -1):\n",
        "            z = torch.randn(n_sample, *size).to(device) if i > 1 else 0\n",
        "            eps = self.eps_model(x_i, i / self.n_T)\n",
        "            x_i = (\n",
        "                self.oneover_sqrta[i] * (x_i - eps * self.mab_over_sqrtmab[i])\n",
        "                + self.sqrt_beta_t[i] * z\n",
        "            )\n",
        "\n",
        "        return x_i\n",
        "\n",
        "\n",
        "def train_mnist(n_epoch: int = 1, device=\"cuda:0\") -> None:\n",
        "\n",
        "    ddpm = DDPM(eps_model=DummyEpsModel(1), betas=(1e-4, 0.02), n_T=1000)\n",
        "    ddpm.to(device)\n",
        "\n",
        "    tf = transforms.Compose(\n",
        "        [transforms.ToTensor(), transforms.Normalize((0.5,), (1.0))]\n",
        "    )\n",
        "\n",
        "    dataset = MNIST(\n",
        "        \"./data\",\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=tf,\n",
        "    )\n",
        "    dataloader = DataLoader(dataset, batch_size=128, shuffle=True, num_workers=20)\n",
        "    optim = torch.optim.Adam(ddpm.parameters(), lr=2e-4)\n",
        "\n",
        "    for i in range(n_epoch):\n",
        "        ddpm.train()\n",
        "\n",
        "        pbar = tqdm(dataloader)\n",
        "        loss_ema = None\n",
        "        for x, _ in pbar:\n",
        "            optim.zero_grad()\n",
        "            x = x.to(device)\n",
        "            loss = ddpm(x)\n",
        "            loss.backward()\n",
        "            if loss_ema is None:\n",
        "                loss_ema = loss.item()\n",
        "            else:\n",
        "                loss_ema = 0.9 * loss_ema + 0.1 * loss.item()\n",
        "            pbar.set_description(f\"loss: {loss_ema:.4f}\")\n",
        "            optim.step()\n",
        "\n",
        "        ddpm.eval()\n",
        "        with torch.no_grad():\n",
        "            xh = ddpm.sample(16, (1, 28, 28), device)\n",
        "            grid = make_grid(xh, nrow=4)\n",
        "            save_image(grid, f\"/content/images/ddpm_sample_{i}.png\")\n",
        "\n",
        "            # save model\n",
        "            torch.save(ddpm.state_dict(), f\"./ddpm_mnist.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_mnist()"
      ],
      "metadata": {
        "id": "3qhBGfKtuIJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Simple Unet Structure.\n",
        "\"\"\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Conv3(nn.Module):\n",
        "    def __init__(\n",
        "        self, in_channels: int, out_channels: int, is_res: bool = False\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
        "            nn.GroupNorm(8, out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
        "            nn.GroupNorm(8, out_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
        "            nn.GroupNorm(8, out_channels),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.is_res = is_res\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.main(x)\n",
        "        if self.is_res:\n",
        "            x = x + self.conv(x)\n",
        "            return x / 1.414\n",
        "        else:\n",
        "            return self.conv(x)\n",
        "\n",
        "\n",
        "class UnetDown(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int) -> None:\n",
        "        super(UnetDown, self).__init__()\n",
        "        layers = [Conv3(in_channels, out_channels), nn.MaxPool2d(2)]\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "class UnetUp(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int) -> None:\n",
        "        super(UnetUp, self).__init__()\n",
        "        layers = [\n",
        "            nn.ConvTranspose2d(in_channels, out_channels, 2, 2),\n",
        "            Conv3(out_channels, out_channels),\n",
        "            Conv3(out_channels, out_channels),\n",
        "        ]\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, skip: torch.Tensor) -> torch.Tensor:\n",
        "        x = torch.cat((x, skip), 1)\n",
        "        x = self.model(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class TimeSiren(nn.Module):\n",
        "    def __init__(self, emb_dim: int) -> None:\n",
        "        super(TimeSiren, self).__init__()\n",
        "\n",
        "        self.lin1 = nn.Linear(1, emb_dim, bias=False)\n",
        "        self.lin2 = nn.Linear(emb_dim, emb_dim)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = x.view(-1, 1)\n",
        "        x = torch.sin(self.lin1(x))\n",
        "        x = self.lin2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class NaiveUnet(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int, n_feat: int = 256) -> None:\n",
        "        super(NaiveUnet, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "        self.n_feat = n_feat\n",
        "\n",
        "        self.init_conv = Conv3(in_channels, n_feat, is_res=True)\n",
        "\n",
        "        self.down1 = UnetDown(n_feat, n_feat)\n",
        "        self.down2 = UnetDown(n_feat, 2 * n_feat)\n",
        "        self.down3 = UnetDown(2 * n_feat, 2 * n_feat)\n",
        "\n",
        "        self.to_vec = nn.Sequential(nn.AvgPool2d(4), nn.ReLU())\n",
        "\n",
        "        self.timeembed = TimeSiren(2 * n_feat)\n",
        "\n",
        "        self.up0 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(2 * n_feat, 2 * n_feat, 4, 4),\n",
        "            nn.GroupNorm(8, 2 * n_feat),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.up1 = UnetUp(4 * n_feat, 2 * n_feat)\n",
        "        self.up2 = UnetUp(4 * n_feat, n_feat)\n",
        "        self.up3 = UnetUp(2 * n_feat, n_feat)\n",
        "        self.out = nn.Conv2d(2 * n_feat, self.out_channels, 3, 1, 1)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "        x = self.init_conv(x)\n",
        "\n",
        "        down1 = self.down1(x)\n",
        "        down2 = self.down2(down1)\n",
        "        down3 = self.down3(down2)\n",
        "\n",
        "        thro = self.to_vec(down3)\n",
        "        temb = self.timeembed(t).view(-1, self.n_feat * 2, 1, 1)\n",
        "\n",
        "        thro = self.up0(thro + temb)\n",
        "\n",
        "        up1 = self.up1(thro, down3) + temb\n",
        "        up2 = self.up2(up1, down2)\n",
        "        up3 = self.up3(up2, down1)\n",
        "\n",
        "        out = self.out(torch.cat((up3, x), 1))\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "goLIIwvk5jOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, Tuple\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "class DDPM(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        eps_model: nn.Module,\n",
        "        betas: Tuple[float, float],\n",
        "        n_T: int,\n",
        "        criterion: nn.Module = nn.MSELoss(),\n",
        "    ) -> None:\n",
        "        super(DDPM, self).__init__()\n",
        "        self.eps_model = eps_model\n",
        "\n",
        "        # register_buffer allows us to freely access these tensors by name. It helps device placement.\n",
        "        for k, v in ddpm_schedules(betas[0], betas[1], n_T).items():\n",
        "            self.register_buffer(k, v)\n",
        "\n",
        "        self.n_T = n_T\n",
        "        self.criterion = criterion\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Makes forward diffusion x_t, and tries to guess epsilon value from x_t using eps_model.\n",
        "        This implements Algorithm 1 in the paper.\n",
        "        \"\"\"\n",
        "\n",
        "        _ts = torch.randint(1, self.n_T + 1, (x.shape[0],)).to(x.device)\n",
        "        # t ~ Uniform(0, n_T)\n",
        "        eps = torch.randn_like(x)  # eps ~ N(0, 1)\n",
        "\n",
        "        x_t = (\n",
        "            self.sqrtab[_ts, None, None, None] * x\n",
        "            + self.sqrtmab[_ts, None, None, None] * eps\n",
        "        )  # This is the x_t, which is sqrt(alphabar) x_0 + sqrt(1-alphabar) * eps\n",
        "        # We should predict the \"error term\" from this x_t. Loss is what we return.\n",
        "\n",
        "        return self.criterion(eps, self.eps_model(x_t, _ts / self.n_T))\n",
        "\n",
        "    def sample(self, n_sample: int, size, device) -> torch.Tensor:\n",
        "\n",
        "        x_i = torch.randn(n_sample, *size).to(device)  # x_T ~ N(0, 1)\n",
        "\n",
        "        # This samples accordingly to Algorithm 2. It is exactly the same logic.\n",
        "        for i in range(self.n_T, 0, -1):\n",
        "            z = torch.randn(n_sample, *size).to(device) if i > 1 else 0\n",
        "            eps = self.eps_model(\n",
        "                x_i, torch.tensor(i / self.n_T).to(device).repeat(n_sample, 1)\n",
        "            )\n",
        "            x_i = (\n",
        "                self.oneover_sqrta[i] * (x_i - eps * self.mab_over_sqrtmab[i])\n",
        "                + self.sqrt_beta_t[i] * z\n",
        "            )\n",
        "\n",
        "        return x_i\n",
        "\n",
        "\n",
        "def ddpm_schedules(beta1: float, beta2: float, T: int) -> Dict[str, torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Returns pre-computed schedules for DDPM sampling, training process.\n",
        "    \"\"\"\n",
        "    assert beta1 < beta2 < 1.0, \"beta1 and beta2 must be in (0, 1)\"\n",
        "\n",
        "    beta_t = (beta2 - beta1) * torch.arange(0, T + 1, dtype=torch.float32) / T + beta1\n",
        "    sqrt_beta_t = torch.sqrt(beta_t)\n",
        "    alpha_t = 1 - beta_t\n",
        "    log_alpha_t = torch.log(alpha_t)\n",
        "    alphabar_t = torch.cumsum(log_alpha_t, dim=0).exp()\n",
        "\n",
        "    sqrtab = torch.sqrt(alphabar_t)\n",
        "    oneover_sqrta = 1 / torch.sqrt(alpha_t)\n",
        "\n",
        "    sqrtmab = torch.sqrt(1 - alphabar_t)\n",
        "    mab_over_sqrtmab_inv = (1 - alpha_t) / sqrtmab\n",
        "\n",
        "    return {\n",
        "        \"alpha_t\": alpha_t,  # \\alpha_t\n",
        "        \"oneover_sqrta\": oneover_sqrta,  # 1/\\sqrt{\\alpha_t}\n",
        "        \"sqrt_beta_t\": sqrt_beta_t,  # \\sqrt{\\beta_t}\n",
        "        \"alphabar_t\": alphabar_t,  # \\bar{\\alpha_t}\n",
        "        \"sqrtab\": sqrtab,  # \\sqrt{\\bar{\\alpha_t}}\n",
        "        \"sqrtmab\": sqrtmab,  # \\sqrt{1-\\bar{\\alpha_t}}\n",
        "        \"mab_over_sqrtmab\": mab_over_sqrtmab_inv,  # (1-\\alpha_t)/\\sqrt{1-\\bar{\\alpha_t}}\n",
        "    }"
      ],
      "metadata": {
        "id": "QV3QjCFT5rml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, Tuple\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# https://arxiv.org/abs/2010.02502\n",
        "class DDIM(DDPM):\n",
        "    def __init__(\n",
        "            self,\n",
        "            eps_model: nn.Module,\n",
        "            betas: Tuple[float, float],\n",
        "            eta: float,\n",
        "            n_T: int,\n",
        "            criterion: nn.Module = nn.MSELoss(),\n",
        "    ) -> None:\n",
        "        super(DDIM, self).__init__(eps_model, betas, n_T, criterion)\n",
        "        self.eta = eta\n",
        "\n",
        "    # modified from https://github.com/ermongroup/ddim/blob/51cb290f83049e5381b09a4cc0389f16a4a02cc9/functions/denoising.py#L10-L32\n",
        "    def sample(self, n_sample: int, size, device) -> torch.Tensor:\n",
        "        x_i = torch.randn(n_sample, *size).to(device)  # x_T ~ N(0, 1)\n",
        "\n",
        "        for i in range(self.n_T, 1, -1):\n",
        "            z = torch.randn(n_sample, *size).to(device) if i > 1 else 0\n",
        "            eps = self.eps_model(x_i, torch.tensor(i / self.n_T).to(device).repeat(n_sample, 1))\n",
        "            x0_t = (x_i - eps * (1 - self.alphabar_t[i]).sqrt()) / self.alphabar_t[i].sqrt()\n",
        "            c1 = self.eta * ((1 - self.alphabar_t[i] / self.alphabar_t[i - 1]) * (1 - self.alphabar_t[i - 1]) / (\n",
        "                    1 - self.alphabar_t[i])).sqrt()\n",
        "            c2 = ((1 - self.alphabar_t[i - 1]) - c1 ** 2).sqrt()\n",
        "            x_i = self.alphabar_t[i - 1].sqrt() * x0_t + c1 * z + c2 * eps\n",
        "\n",
        "        return x_i"
      ],
      "metadata": {
        "id": "u2m3aNmL53Us"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, Optional, Tuple\n",
        "from sympy import Ci\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image, make_grid\n",
        "\n",
        "# from mindiffusion.unet import NaiveUnet\n",
        "# from mindiffusion.ddpm import DDPM\n",
        "\n",
        "\n",
        "def train_cifar10(\n",
        "    n_epoch: int = 100, device: str = \"cuda:0\", load_pth: Optional[str] = None\n",
        ") -> None:\n",
        "\n",
        "    ddpm = DDPM(eps_model=NaiveUnet(3, 3, n_feat=128), betas=(1e-4, 0.02), n_T=1000)\n",
        "\n",
        "    if load_pth is not None:\n",
        "        ddpm.load_state_dict(torch.load(\"ddpm_cifar.pth\"))\n",
        "\n",
        "    ddpm.to(device)\n",
        "\n",
        "    tf = transforms.Compose(\n",
        "        [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        "    )\n",
        "\n",
        "    dataset = CIFAR10(\n",
        "        \"./data\",\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=tf,\n",
        "    )\n",
        "\n",
        "    dataloader = DataLoader(dataset, batch_size=512, shuffle=True, num_workers=16)\n",
        "    optim = torch.optim.Adam(ddpm.parameters(), lr=1e-5)\n",
        "\n",
        "    for i in range(n_epoch):\n",
        "        print(f\"Epoch {i} : \")\n",
        "        ddpm.train()\n",
        "\n",
        "        pbar = tqdm(dataloader)\n",
        "        loss_ema = None\n",
        "        for x, _ in pbar:\n",
        "            optim.zero_grad()\n",
        "            x = x.to(device)\n",
        "            loss = ddpm(x)\n",
        "            loss.backward()\n",
        "            if loss_ema is None:\n",
        "                loss_ema = loss.item()\n",
        "            else:\n",
        "                loss_ema = 0.9 * loss_ema + 0.1 * loss.item()\n",
        "            pbar.set_description(f\"loss: {loss_ema:.4f}\")\n",
        "            optim.step()\n",
        "\n",
        "        ddpm.eval()\n",
        "        with torch.no_grad():\n",
        "            xh = ddpm.sample(8, (3, 32, 32), device)\n",
        "            xset = torch.cat([xh, x[:8]], dim=0)\n",
        "            grid = make_grid(xset, normalize=True, value_range=(-1, 1), nrow=4)\n",
        "            save_image(grid, f\"/contents/images/ddpm_sample_cifar{i}.png\")\n",
        "\n",
        "            # save model\n",
        "            torch.save(ddpm.state_dict(), f\"./ddpm_cifar.pth\")\n",
        "\n",
        "\n",
        "train_cifar10()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0u4Whgf2uPFA",
        "outputId": "ff7cdf8c-29e5-430e-9637-e9879795414b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 1.1161:  15%|█▌        | 15/98 [00:15<01:02,  1.32it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Lo3Ek-NW5Ujk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}